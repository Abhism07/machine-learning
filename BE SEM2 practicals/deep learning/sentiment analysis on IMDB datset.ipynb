{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b26cae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb # Load the data, keeping only 10,000 of the most frequently occuring words\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1b79b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type([max(sequence) for sequence in train_data]))\n",
    "\n",
    "# Find the maximum of all max indexes\n",
    "max([max(sequence) for sequence in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ac6743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62a1d93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "       ...,\n",
       "       list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 2, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 2, 325, 725, 134, 2, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 2, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 2, 7750, 5, 4241, 18, 4, 8497, 2, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 2, 4, 3586, 2]),\n",
       "       list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "       list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 2, 21, 27, 9685, 6139, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 2, 2, 544, 5, 383, 1271, 848, 1468, 2, 497, 2, 8, 1597, 8778, 2, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b96f9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's quickly decode a review\n",
    "\n",
    "# step 1: load the dictionary mappings from word to integer index\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "# step 2: reverse word index to map integer indexes to their respective words\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "# Step 3: decode the review, mapping integer indices to words\n",
    "#\n",
    "# indices are off by 3 because 0, 1, and 2 are reserverd indices for \"padding\", \"Start of sequence\" and \"unknown\"\n",
    "decoded_review = ' '.join([reverse_word_index.get(i-3, '?') for i in train_data[0]])\n",
    "\n",
    "decoded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76b47ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))    # Creates an all zero matrix of shape (len(sequences),10K)\n",
    "    for i,sequence in enumerate(sequences):\n",
    "        results[i,sequence] = 1                        # Sets specific indices of results[i] to 1s\n",
    "    return results\n",
    "\n",
    "# Vectorize training Data\n",
    "X_train = vectorize_sequences(train_data)\n",
    "\n",
    "# Vectorize testing Data\n",
    "X_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "538f19fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cc7379",
   "metadata": {},
   "source": [
    "# VECTORIZE LABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d2fc3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['negative','positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26f0ba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test  = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e5c32ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7883ae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models \n",
    "from keras import layers \n",
    "model = models.Sequential() \n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu')) \n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a35227dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras import losses \n",
    "from keras import metrics \n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001), loss = losses.binary_crossentropy, metrics = [metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d945c4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Input for Validation\n",
    "X_val = X_train[:10000]\n",
    "partial_X_train = X_train[10000:] # Labels for validation \n",
    "y_val = y_train[:10000] \n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aeb11ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 1s 33ms/step - loss: 0.0760 - binary_accuracy: 0.9795 - val_loss: 0.3393 - val_binary_accuracy: 0.8789\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.0652 - binary_accuracy: 0.9829 - val_loss: 0.3546 - val_binary_accuracy: 0.8786\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.0536 - binary_accuracy: 0.9867 - val_loss: 0.3763 - val_binary_accuracy: 0.8777\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.0441 - binary_accuracy: 0.9909 - val_loss: 0.3987 - val_binary_accuracy: 0.8775\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.0388 - binary_accuracy: 0.9908 - val_loss: 0.4206 - val_binary_accuracy: 0.8720\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.0296 - binary_accuracy: 0.9948 - val_loss: 0.4411 - val_binary_accuracy: 0.8757\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 1s 32ms/step - loss: 0.0268 - binary_accuracy: 0.9955 - val_loss: 0.4616 - val_binary_accuracy: 0.8730\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.0210 - binary_accuracy: 0.9976 - val_loss: 0.4836 - val_binary_accuracy: 0.8736\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 1s 32ms/step - loss: 0.0183 - binary_accuracy: 0.9975 - val_loss: 0.5115 - val_binary_accuracy: 0.8741\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.0177 - binary_accuracy: 0.9969 - val_loss: 0.5361 - val_binary_accuracy: 0.8727\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_X_train, partial_y_train, epochs=10, batch_size=512, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e488501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 77ms/step\n",
      "[[0.9932654]] positive\n"
     ]
    }
   ],
   "source": [
    "# Making Predictions for testing data np.set_printoptions(suppress=True) \n",
    "import numpy as np\n",
    "\n",
    "result = model.predict(np.expand_dims(X_test[10],axis=0))\n",
    "print(result,class_names[int(result[0]>0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "868a42ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1436"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7704f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "new=[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d73d1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new=vectorize_sequences(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acef4d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step\n",
      "[[[0.56623393]\n",
      "  [0.50607634]\n",
      "  [0.58161604]\n",
      "  [0.44663984]\n",
      "  [0.44310692]\n",
      "  [0.7038785 ]\n",
      "  [0.36259097]\n",
      "  [0.48601788]\n",
      "  [0.4780071 ]\n",
      "  [0.5333006 ]\n",
      "  [0.4448937 ]\n",
      "  [0.64268583]\n",
      "  [0.5300351 ]\n",
      "  [0.49723768]\n",
      "  [0.5509509 ]\n",
      "  [0.54616517]\n",
      "  [0.50228536]\n",
      "  [0.51123834]\n",
      "  [0.5181145 ]\n",
      "  [0.65732217]\n",
      "  [0.4208461 ]\n",
      "  [0.44310692]\n",
      "  [0.42432767]\n",
      "  [0.50684327]\n",
      "  [0.46677512]\n",
      "  [0.44575912]\n",
      "  [0.521864  ]\n",
      "  [0.5927835 ]\n",
      "  [0.5093461 ]\n",
      "  [0.72593755]\n",
      "  [0.40569875]\n",
      "  [0.5181145 ]\n",
      "  [0.65870106]\n",
      "  [0.5509509 ]\n",
      "  [0.4998693 ]\n",
      "  [0.50684327]\n",
      "  [0.3870872 ]\n",
      "  [0.521864  ]\n",
      "  [0.51262236]\n",
      "  [0.5200124 ]\n",
      "  [0.48123908]\n",
      "  [0.5509509 ]\n",
      "  [0.4998693 ]\n",
      "  [0.5519966 ]\n",
      "  [0.4385519 ]\n",
      "  [0.5177299 ]\n",
      "  [0.5328816 ]\n",
      "  [0.5575095 ]\n",
      "  [0.5759012 ]\n",
      "  [0.74394375]\n",
      "  [0.5509509 ]\n",
      "  [0.5151417 ]\n",
      "  [0.46677512]\n",
      "  [0.44663984]\n",
      "  [0.5167568 ]\n",
      "  [0.5183209 ]\n",
      "  [0.3769946 ]\n",
      "  [0.52735543]\n",
      "  [0.50607634]\n",
      "  [0.58161604]\n",
      "  [0.5509509 ]\n",
      "  [0.7175779 ]\n",
      "  [0.40856895]\n",
      "  [0.63912535]\n",
      "  [0.5509509 ]\n",
      "  [0.58161604]\n",
      "  [0.4312685 ]\n",
      "  [0.74213576]\n",
      "  [0.58588785]\n",
      "  [0.44663984]\n",
      "  [0.44310692]\n",
      "  [0.7038785 ]\n",
      "  [0.5575095 ]\n",
      "  [0.43399802]\n",
      "  [0.5218428 ]\n",
      "  [0.5759012 ]\n",
      "  [0.61430913]\n",
      "  [0.5509509 ]\n",
      "  [0.58161604]\n",
      "  [0.5177299 ]\n",
      "  [0.5829191 ]\n",
      "  [0.5177299 ]\n",
      "  [0.58588785]\n",
      "  [0.44663984]\n",
      "  [0.49619576]\n",
      "  [0.5597728 ]\n",
      "  [0.521864  ]\n",
      "  [0.5181145 ]\n",
      "  [0.46345773]\n",
      "  [0.53681386]\n",
      "  [0.58588785]\n",
      "  [0.45699772]\n",
      "  [0.6706247 ]\n",
      "  [0.45699772]\n",
      "  [0.5485858 ]\n",
      "  [0.5181145 ]\n",
      "  [0.5509509 ]\n",
      "  [0.51342237]\n",
      "  [0.5941931 ]\n",
      "  [0.44663984]\n",
      "  [0.72593755]\n",
      "  [0.5300351 ]\n",
      "  [0.71721935]\n",
      "  [0.5015575 ]\n",
      "  [0.5509509 ]\n",
      "  [0.5341906 ]\n",
      "  [0.58588785]\n",
      "  [0.44663984]\n",
      "  [0.5575095 ]\n",
      "  [0.43294933]\n",
      "  [0.5181145 ]\n",
      "  [0.65732217]\n",
      "  [0.60563666]\n",
      "  [0.5665597 ]\n",
      "  [0.50228536]\n",
      "  [0.6050578 ]\n",
      "  [0.44367006]\n",
      "  [0.65732217]\n",
      "  [0.70930004]\n",
      "  [0.5015575 ]\n",
      "  [0.5167568 ]\n",
      "  [0.58161604]\n",
      "  [0.58588785]\n",
      "  [0.6344603 ]\n",
      "  [0.51465505]\n",
      "  [0.48379955]\n",
      "  [0.6362852 ]\n",
      "  [0.5181145 ]\n",
      "  [0.50607634]\n",
      "  [0.72570395]\n",
      "  [0.44663984]\n",
      "  [0.6654977 ]\n",
      "  [0.521864  ]\n",
      "  [0.45699772]\n",
      "  [0.5509509 ]\n",
      "  [0.52797973]\n",
      "  [0.55371904]\n",
      "  [0.69464153]\n",
      "  [0.5218428 ]\n",
      "  [0.51123834]\n",
      "  [0.5509509 ]\n",
      "  [0.521864  ]\n",
      "  [0.50505   ]\n",
      "  [0.36483657]\n",
      "  [0.5181145 ]\n",
      "  [0.5517875 ]\n",
      "  [0.50228536]\n",
      "  [0.4312685 ]\n",
      "  [0.44310692]\n",
      "  [0.7038785 ]\n",
      "  [0.47595072]\n",
      "  [0.5325728 ]\n",
      "  [0.5773328 ]\n",
      "  [0.36998117]\n",
      "  [0.5505976 ]\n",
      "  [0.50505   ]\n",
      "  [0.5509509 ]\n",
      "  [0.521864  ]\n",
      "  [0.6536224 ]\n",
      "  [0.5759012 ]\n",
      "  [0.5940637 ]\n",
      "  [0.5091927 ]\n",
      "  [0.5509509 ]\n",
      "  [0.6157789 ]\n",
      "  [0.5218428 ]\n",
      "  [0.6231468 ]\n",
      "  [0.52247256]\n",
      "  [0.59943515]\n",
      "  [0.696783  ]\n",
      "  [0.52851236]\n",
      "  [0.5325728 ]\n",
      "  [0.507778  ]\n",
      "  [0.5167568 ]\n",
      "  [0.60182655]\n",
      "  [0.3245307 ]\n",
      "  [0.5597728 ]\n",
      "  [0.5509509 ]\n",
      "  [0.39459884]\n",
      "  [0.58161604]\n",
      "  [0.56333727]\n",
      "  [0.49994984]\n",
      "  [0.47595072]\n",
      "  [0.5325728 ]\n",
      "  [0.72593755]\n",
      "  [0.5181145 ]\n",
      "  [0.47338083]\n",
      "  [0.5211099 ]\n",
      "  [0.6268246 ]\n",
      "  [0.5597728 ]\n",
      "  [0.5665597 ]\n",
      "  [0.50228536]\n",
      "  [0.51465505]\n",
      "  [0.5563235 ]\n",
      "  [0.4997937 ]\n",
      "  [0.65732217]\n",
      "  [0.5940637 ]\n",
      "  [0.5509509 ]\n",
      "  [0.39459884]\n",
      "  [0.5333006 ]\n",
      "  [0.44663984]\n",
      "  [0.5575095 ]\n",
      "  [0.6771091 ]\n",
      "  [0.5091927 ]\n",
      "  [0.58588785]\n",
      "  [0.44663984]\n",
      "  [0.66565984]\n",
      "  [0.5181145 ]\n",
      "  [0.44663984]\n",
      "  [0.5102237 ]\n",
      "  [0.59095323]\n",
      "  [0.5794415 ]\n",
      "  [0.59943515]\n",
      "  [0.5218428 ]\n",
      "  [0.44663984]\n",
      "  [0.6740472 ]\n",
      "  [0.52735543]\n",
      "  [0.58688956]\n",
      "  [0.59943515]]] positive\n"
     ]
    }
   ],
   "source": [
    "result1 = model.predict(np.expand_dims(new,axis=0))\n",
    "print(result1,class_names[int(result[0]>0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfdd898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
