{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3de38da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 6s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "246f6d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83356d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),  # Flatten the input images\n",
    "    layers.Dense(128, activation='relu'),  # First hidden layer with 128 neurons\n",
    "    layers.Dense(10, activation='softmax') # Output layer with 10 neurons (one for each class)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f326b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "524a6809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2343 - accuracy: 0.9131 - val_loss: 0.3321 - val_accuracy: 0.8879\n",
      "Epoch 2/15\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2256 - accuracy: 0.9156 - val_loss: 0.3310 - val_accuracy: 0.8838\n",
      "Epoch 3/15\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2189 - accuracy: 0.9187 - val_loss: 0.3240 - val_accuracy: 0.8895\n",
      "Epoch 4/15\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2098 - accuracy: 0.9212 - val_loss: 0.3466 - val_accuracy: 0.8826\n",
      "Epoch 5/15\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2048 - accuracy: 0.9219 - val_loss: 0.3417 - val_accuracy: 0.8899\n",
      "Epoch 6/15\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1993 - accuracy: 0.9244 - val_loss: 0.3519 - val_accuracy: 0.8879\n",
      "Epoch 7/15\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1930 - accuracy: 0.9274 - val_loss: 0.3272 - val_accuracy: 0.8901\n",
      "Epoch 8/15\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1860 - accuracy: 0.9299 - val_loss: 0.3536 - val_accuracy: 0.8870\n",
      "Epoch 9/15\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1836 - accuracy: 0.9312 - val_loss: 0.3726 - val_accuracy: 0.8831\n",
      "Epoch 10/15\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1772 - accuracy: 0.9331 - val_loss: 0.3622 - val_accuracy: 0.8797\n",
      "Epoch 11/15\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1716 - accuracy: 0.9355 - val_loss: 0.3614 - val_accuracy: 0.8884\n",
      "Epoch 12/15\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1686 - accuracy: 0.9366 - val_loss: 0.3725 - val_accuracy: 0.8854\n",
      "Epoch 13/15\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1644 - accuracy: 0.9376 - val_loss: 0.3605 - val_accuracy: 0.8909\n",
      "Epoch 14/15\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1604 - accuracy: 0.9385 - val_loss: 0.3577 - val_accuracy: 0.8939\n",
      "Epoch 15/15\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1557 - accuracy: 0.9416 - val_loss: 0.3510 - val_accuracy: 0.8926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1a6807ad150>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=15, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3c4eb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.3446 - accuracy: 0.8787\n",
      "Test Accuracy: 0.8787000179290771\n",
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Step 7: Make predictions\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b2cbb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4401240e-07, 4.6634896e-12, 6.1871546e-08, ..., 1.1655721e-03,\n",
       "        5.9301613e-09, 9.9880290e-01],\n",
       "       [2.5683017e-05, 9.3098229e-13, 9.9780661e-01, ..., 1.1695226e-13,\n",
       "        7.5629822e-11, 1.7840772e-14],\n",
       "       [3.0144005e-08, 1.0000000e+00, 5.8227912e-15, ..., 9.7507999e-19,\n",
       "        5.4927617e-13, 3.8437569e-16],\n",
       "       ...,\n",
       "       [1.6888158e-06, 1.2654486e-10, 8.4502784e-07, ..., 1.4673540e-08,\n",
       "        9.9997330e-01, 8.4997330e-13],\n",
       "       [3.4210808e-07, 9.9993956e-01, 1.7038357e-10, ..., 3.1385243e-13,\n",
       "        3.0040348e-09, 7.9666352e-12],\n",
       "       [4.2383515e-05, 9.2283745e-09, 2.5646224e-05, ..., 1.3343723e-03,\n",
       "        6.4688873e-05, 1.2795242e-05]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46a6665b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m img\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrouser.jpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Make predictions on the sample images\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Define class labels\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:959\u001b[0m, in \u001b[0;36mTensorShape.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    958\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v2_behavior:\n\u001b[1;32m--> 959\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dims\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    960\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims[key]\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select random images from the test set\n",
    "num_samples = 5\n",
    "random_indices = np.random.choice(len(test_images), num_samples, replace=False)\n",
    "sample_images = test_images[random_indices]\n",
    "sample_labels = test_labels[random_indices]\n",
    "img= \"trouser.jpeg\"\n",
    "# Make predictions on the sample images\n",
    "predictions = model.predict(img)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# Show images with their predicted and true labels\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(num_samples):\n",
    "    plt.subplot(1, num_samples, i + 1)\n",
    "    plt.imshow(sample_images[i], cmap='gray')\n",
    "    plt.title(f\"True: {class_labels[sample_labels[i]]}\\nPredicted: {class_labels[predicted_labels[i]]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea84c53f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
